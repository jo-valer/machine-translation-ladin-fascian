{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "In this notebook we evaluate the model's translation on:\n",
    "- In-domain Ladin\n",
    "- Out-of-domain Ladin (Transfer Learning Across Domains)\n",
    "- Italian-to-English (Forgetting of previous knowledge)\n",
    "\n",
    "**Note**: For the sake of simplicity, we show the evaluation on a single model. However, the evaluation can be done for any model by simply changing `MODEL_LOAD_PATH`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers sacrebleu bert-score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm.auto import tqdm\n",
    "import sacrebleu\n",
    "from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/jo-valer/machine-translation-ladin-fascian/main/data/test_id.tsv\n",
    "!wget https://raw.githubusercontent.com/jo-valer/machine-translation-ladin-fascian/main/data/test_ood.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_id.tsv', sep=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "df_test_ood = pd.read_csv('test_ood.tsv', sep=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'jo-valer/nllb-multi' or 'jo-valer/nllb-pivot'\n",
    "MODEL_LOAD_PATH = 'jo-valer/nllb-multi'\n",
    "\n",
    "tokenizer = NllbTokenizer.from_pretrained(MODEL_LOAD_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_LOAD_PATH).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "\n",
    "lang_codes = {\n",
    "  \"it\": [\"italian\", \"ita_Latn\"],\n",
    "  \"en\": [\"english\", \"eng_Latn\"],\n",
    "  \"lld\": [\"ladin\", \"fur_Latn\"]\n",
    "}\n",
    "\n",
    "def translate(text, src_lang='fur_Latn', tgt_lang='eng_Latn', a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    outputs = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def test_loop(data=df_test, column='en_translated', src='lld', tgt='en'):\n",
    "    model.eval()\n",
    "    data[column] = [translate(t, lang_codes[src][1], lang_codes[tgt][1])[0] for t in tqdm(data[lang_codes[src][0]])]\n",
    "    bleu_score = bleu_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    chrf_score = chrf_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    P, R, F1 = scorer.score(data[column].tolist(), data[lang_codes[tgt][0]].tolist())\n",
    "    print(\"\\nSrc:\", src, \"Tgt:\", tgt)\n",
    "    print(f\"BLEU = {bleu_score:.2f} / chrF++ = {chrf_score:.2f} / BERTscoreF1 = {(F1.mean()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-domain Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladin-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English-Ladin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='lld_translated_en', src='en', tgt='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladin-Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='it_translated', src='lld', tgt='it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Italian-Ladin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='lld_translated_it', src='it', tgt='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-domain Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladin-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(data=df_test_ood, column='en_translated_ood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English-Ladin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(data=df_test_ood, column='lld_translated_en_ood', src='en', tgt='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladin-Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(data=df_test_ood, column='it_translated_ood', src='lld', tgt='it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Italian-Ladin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(data=df_test_ood, column='lld_translated_it_ood', src='it', tgt='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forgetting of previous knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Italian to English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated', src='it', tgt='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test English to Italian translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='it_translated', src='en', tgt='it')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
