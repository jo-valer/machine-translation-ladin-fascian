{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Experiments\n",
    "Firstly, we evaluate the performance of the pre-trained models in Italian-to-English translation, in order to have a reference for subsequent experiments. We also evaluate the performance of the models to translate from Ladin to English, either considering Ladin sentences as if they were written in Italian, French, or Friulian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece transformers sacrebleu bert-score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import NllbTokenizer, AutoModelForSeq2SeqLM, AutoTokenizer, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import sacrebleu\n",
    "from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/jo-valer/machine-translation-ladin-fascian/main/data/test_id.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_id.tsv', sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We use three metrics: BLEU, chrF++ and BERTScore F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_calc = sacrebleu.BLEU()\n",
    "chrf_calc = sacrebleu.CHRF(word_order=2)\n",
    "scorer = BERTScorer(model_type='bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPUS-MT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian-to-English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-it-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-it-en\").cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "    \"it\": [\"italian\", \"it\"],\n",
    "    \"en\": [\"english\", \"en\"],\n",
    "    \"lld\": [\"ladin\", \"lld\"]\n",
    "}\n",
    "\n",
    "def translate(text, src_lang='lld_Latn', tgt_lang='eng_Latn', a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    outputs = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def test_loop(data=df_test, column='en_translated', src='lld', tgt='en', data_src='lld'):\n",
    "    data[column] = [translate(t, lang_codes[src][1], lang_codes[tgt][1])[0] for t in tqdm(data[lang_codes[data_src][0]])]\n",
    "    bleu_score = bleu_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    chrf_score = chrf_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    P, R, F1 = scorer.score(data[column].tolist(), data[lang_codes[tgt][0]].tolist())\n",
    "    print(f\"BLEU = {bleu_score:.2f} / chrF++ = {chrf_score:.2f} / BERTscoreF1 = {(F1.mean()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Italian to English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated', src='it', tgt='en', data_src='it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_it', src='it', tgt='en', data_src='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English-to-Italian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-it\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-it\").cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "    \"it\": [\"italian\", \"it\"],\n",
    "    \"en\": [\"english\", \"en\"],\n",
    "    \"lld\": [\"ladin\", \"lld\"]\n",
    "}\n",
    "\n",
    "def translate(text, src_lang='lld_Latn', tgt_lang='eng_Latn', a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    outputs = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def test_loop(data=df_test, column='en_translated', src='lld', tgt='en', data_src='lld'):\n",
    "    data[column] = [translate(t, lang_codes[src][1], lang_codes[tgt][1])[0] for t in tqdm(data[lang_codes[data_src][0]])]\n",
    "    bleu_score = bleu_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    chrf_score = chrf_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    P, R, F1 = scorer.score(data[column].tolist(), data[lang_codes[tgt][0]].tolist())\n",
    "    print(f\"BLEU = {bleu_score:.2f} / chrF++ = {chrf_score:.2f} / BERTscoreF1 = {(F1.mean()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test English to Italian translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='it_translated', src='en', tgt='it', data_src='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2M-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\").cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "    \"it\": [\"italian\", \"it\"],\n",
    "    \"en\": [\"english\", \"en\"],\n",
    "    \"fr\": [\"french\", \"fr\"],\n",
    "    \"lld\": [\"ladin\", \"lld\"]\n",
    "}\n",
    "\n",
    "def translate(text, src_lang='lld_Latn', tgt_lang='eng_Latn', a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    outputs = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.get_lang_id(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def test_loop(data=df_test, column='en_translated', src='lld', tgt='en', data_src='lld'):\n",
    "    data[column] = [translate(t, lang_codes[src][1], lang_codes[tgt][1])[0] for t in tqdm(data[lang_codes[data_src][0]])]\n",
    "    bleu_score = bleu_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    chrf_score = chrf_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    P, R, F1 = scorer.score(data[column].tolist(), data[lang_codes[tgt][0]].tolist())\n",
    "    print(f\"BLEU = {bleu_score:.2f} / chrF++ = {chrf_score:.2f} / BERTscoreF1 = {(F1.mean()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Italian to English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated', src='it', tgt='en', data_src='it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English to Italian translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='it_translated', src='en', tgt='it', data_src='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_it', src='it', tgt='en', data_src='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_fr', src='fr', tgt='en', data_src='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLLB-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = NllbTokenizer.from_pretrained('facebook/nllb-200-distilled-600M')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('facebook/nllb-200-distilled-600M').cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "    \"it\": [\"italian\", \"ita_Latn\"],\n",
    "    \"en\": [\"english\", \"eng_Latn\"],\n",
    "    \"fr\": [\"french\", \"fra_Latn\"],\n",
    "    \"lld\": [\"ladin\", \"lld_Latn\"],\n",
    "    \"fur\": [\"friulian\", \"fur_Latn\"]\n",
    "}\n",
    "\n",
    "def translate(text, src_lang='lld_Latn', tgt_lang='eng_Latn', a=32, b=3, max_input_length=1024, num_beams=4, **kwargs):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "    outputs = model.generate(\n",
    "        **inputs.to(model.device),\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "        num_beams=num_beams,\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def test_loop(data=df_test, column='en_translated', src='lld', tgt='en', data_src='lld'):\n",
    "    data[column] = [translate(t, lang_codes[src][1], lang_codes[tgt][1])[0] for t in tqdm(data[lang_codes[data_src][0]])]\n",
    "    bleu_score = bleu_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    chrf_score = chrf_calc.corpus_score(data[column].tolist(), [data[lang_codes[tgt][0]].tolist()]).score\n",
    "    P, R, F1 = scorer.score(data[column].tolist(), data[lang_codes[tgt][0]].tolist())\n",
    "    print(f\"BLEU = {bleu_score:.2f} / chrF++ = {chrf_score:.2f} / BERTscoreF1 = {(F1.mean()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Italian to English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated', src='it', tgt='en', data_src='it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test English to Italian translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='it_translated', src='en', tgt='it', data_src='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_it', src='it', tgt='en', data_src='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_fr', src='fr', tgt='en', data_src='lld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Ladin to English translation, with Ladin sentences considered as if they were written in Friulian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(column='en_translated_fur', src='fur', tgt='en', data_src='lld')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
